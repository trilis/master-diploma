\documentclass[../thesis.tex]{subfiles}
\begin{document}\label{sec:1}

В данной главе будет даны необходимые определения таких ключевых понятий, как лямбда-исчисление, подстановки и редукции, рассмотрены некоторые классические порядки редукций, такие как нормальный порядок и аппликативный порядок, а также поставлены вопросы относительно оптимальности этих порядков. Также в этой главе будет рассмотрен непосредственый контекст работы, а именно язык Coq, система Ursus и входные данные для рассматриваемой задачи.

\subsection{Редукции термов в лямбда-исчислении}

Лямбда-исчисление \cite{lambda_calculus} --- это математическая система, позволяющая формализовать вычислимость в функциональных языках программирования. Лямбда-исчисление определяется как множество \textit{термов} $T$ вместе с множеством \textit{редукций} $\rightarrow$, описывающих допустимые преобразования термов. В простейшем случае множество термов можно определить как
$$T \ni t ::= \lambda x.\, t \mid x \mid t_1\ t_2$$

Первый случай в этой записи называется \textit{абстракцией} и описывает функцию, принимающую как аргумент некое выражение (переменную) $x$, второй случай описывает обращение к ранее объявленной в абстракции переменной, а третий случай называется \textit{аппликацией} и описывает применение функции к аргументу. Чтобы формально описать семантику лямбда-исчисления, вводятся различные редукции, центральной из которых является \textit{$\beta$-редукция} $\rightarrow_\beta$, формализующая вычисления. Чтобы определить $\beta$-редукцию, введём несколько вспомогательных понятий.

Определим \textit{множество свободных переменных} $FV(t)$ как множество всех переменных в $t$, не имеющих соответствующей абстракции:
$$FV(x) = \{x\},\ FV(t_1\ t_2) = FV(t_1) \cup FV(t_2),\ FV(\lambda x.\, t) = FV(t) \setminus \{x\}$$

Заметим, что переменные в этой системе функционируют как способ связать абстракцию с её аргументом, а конкретные имена этих переменных нам не важны. Чтобы формализовать это наблюдение, определим \textit{$\alpha$-конверсию} как переименование переменной в абстрации на произвольную другую. Согласно конвенции Барендрегта \cite{lambda_calculus}, будем неявно применять $\alpha$-конверсию, так чтобы все переменные имели различные имена, а $\alpha$-эквивалентные (т.е. получаемые друг из друга с помощью $\alpha$-конверсии) термы будем считать равными.

Определим \textit{подстановку} $t [x := u]$ как замену всех вхождений переменной $x$ в терме $t$ на терм $u$:
$$x [x := u] = u\ \ \ \ \ \ \ \ y [x := u] = y\ (x \neq y)$$ $$t_1\ t_2 [x := u] = t_1 [x := u]\ t_2 [x := u]$$ $$\lambda x.\, t [x := u] = \lambda x.\, t \ \ \ \ \ \ \ \ (\lambda y.\, t) [x := u] = \lambda y.\, (t [x := u])\ (x \neq y, y \notin FV(u))$$

Заметим, что подстановка для некоторых аргументов может быть не определена из-за условия $y \notin FV(u)$ в последнем случае, но предварительное применение $\alpha$-конверсии для аргумента $u$ с целью использовать в нём только не используемые в $t$ свободные переменные, позволяет доопределить подстановку.

Определим множество \textit{редексов} терма $t$ как множество всех подтермов $t$ вида $(\lambda x.\, t_1) t_2$. Наличие редекса в терме показывает, что в терме есть функция, которую можно применить к аргументу. Наконец, мы можем определить $\beta$-редукцию как подстановку аргумента в произвольном редексе терма, которая оставляет остальную часть терма без изменений:
$$(\lambda x.\, t_1) t_2 \rightarrow_\beta t_2 [x := t_1]$$

Определим $\rightarrow_\beta^*$ как транзитивное замыкание $\rightarrow_\beta$. Если $t_1 \rightarrow_\beta^* t_2$, то будем говорить, что $t_1$ \textit{редуцируется} к $t_2$. Поскольку в терме может быть несколько редексов, \textit{порядок} (или \textit{стратегия}) \textit{редукции}, то есть последовательность редексов в последовательном применении $\beta$-редукции, может быть различным. Этот факт порождает несколько ключевых вопросов: может ли от выбора стратегии зависеть результат, конечность процесса, и, наконец, оптимальность (т.е. количество шагов редукции).

Будем говорить, что терм $t$ находится в \textit{нормальной форме}, если к нему нельзя применить $\beta$-редукцию, то есть он не содержит редексов. Нормальная форма представляет собой конечный результат вычислений, подобно упрощенной до конкретного числа арифметической формуле. Важным свойством любой системы, основанной на лямбда-исчислении, является \textit{конфлюэнтность}, то есть независимость результата от порядка редукций:
$$t_1 \rightarrow_\beta^* t_1',\ t_2 \rightarrow_\beta^* t_2' \ \Rightarrow\ \exists t.\ t_1' \rightarrow_\beta^* t,\ t_2' \rightarrow_\beta^* t$$

Напрямую из определения конфлюэнтности следует, что если система является конфлюэнтной, то терм не может редуцироваться к разным нормальным формам. Описанная выше простейшая система лямбда-исчисления является конфлюэнтной по теореме Черча-Россера, как и многие другие более сложные и применимые на практике системы, поскольку недетерминированные в этом смысле системы являются менее желательными на практике. Будем называть терм $t'$ \textit{нормальной формой} терма $t$, если $t'$ находится в нормальной форме, а $t$ редуцируется к $t'$. Задача поиска нормальной формы является ключевой при разработке семантики любого функционального языка программирования, поскольку, в практических терминах, решение этой задачи эквивалентно написанию интерпретатора языка. 

Для ответа на вопрос о завершимости введём понятия \textit{сильной} и \textit{слабой нормализуемости}. Терм $t$ является слабо нормализуемым, если у него есть нормальная форма, и сильно нормализуемым, если любая стратегия редукции редуцирует его к нормальной форме за конечное число шагов $\beta$-редукции. Система является сильно (слабо) нормализуемой, если все термы в ней являются сильно (слабо) нормализуемыми.

Описанная выше простейшая система лямбда-исчисления не является ни сильно, ни слабо нормализуемой \cite{lambda_calculus}. На практике это означает, что вычисление кода, соответствующего некоторым термам, может не завершиться, что в некоторых случаях нежелательно (а в слабом случае --- завершимость этого вычисления может зависеть от порядка редукций). Данную проблему можно решать \textit{типизацией} термов, т.е. рассмотрением только подмножества в каком-то смысле корректных термов. Так, просто типизированное лямбда-исчисление является сильно нормализуемым \cite{lambda_calculus}, однако в такой системе становится невозможно описать рекурсию. Более того, любой полный по Тьюрингу язык не может быть сильно нормализуемым, ведь завершаемость всех программ на таком языке противоречила бы проблеме остановки.

Данная работа находится в контексте системы, которая является и конфлюэнтной, и сильно нормализуемой (см. ниже в разделе \ref{coq_problems}), то есть независимо от выбора стратегии редукции, любое вычисление придёт к единственно верному результату за конечное число шагов. Нас же интересует вопросы \textit{оптимальности} стратегий, поскольку даже в системе, удовлетворяющим описанным выше теоретическим свойствам, термы могут редуцироваться к начальной форме за существенно отличающееся и значимое на практике число шагов.

\subsection{Классические порядки редукций} \label{orders}

Мы рассмотрим два классических порядка редукций --- нормальный и аппликативный. 

\textit{Аппликативный} порядок редукции заключается в выборе наиболее вложенного редекса (а из редексов с равной вложенностью --- самого левого). При таком порядке все аргументы абстракции будут вычислены до того, как подставлены. \textit{Нормальный} порядок редукции заключается в выборе наименее вложенного редекса (аналогично, из редексов с равной вложенностью выбирается самый левый).

У этих стратегий есть \textit{слабые} версии, отличающиеся ограничением на $\beta$-редукцию и соответственно определением нормальной формы. Для слабой стратегии запрещены редукции внутри абстракции, то есть, например, слабая стратегия рассматривает терм $(\lambda x.\, (\lambda y.\, y) x)$ как находящийся в нормальной форме. Слабая версия аппликативного порядка называется \textit{вызов по значению} (\textit{call-by-value}), а нормального --- \textit{вызов по имени} (\textit{call-by-name}). Дальнейшие соображения высказаны для аппликативных и нормальных порядков, однако их можно также применить к вызову по значению и вызову по имени соответсвенно.

При условии наличия у терма нормальной формы нормальный порядок всегда редуцирует терм к ней, чего нельзя сказать про аппликативный порядок. Например, для терма $(\lambda x.\, y) (\omega \omega)$, где $y$ --- свободная переменная, а $\omega = \lambda z.\, z z$, нормальный порядок редуцирует внешний редекс, придя к нормальной форме $y$, а аппликативный порядок будет бесконечно редуцировать редекс $\omega \omega$, который редуцируется к себе же. Но даже в сильно нормализуемых системах производительность этих порядков на некоторых примерах может существенно отличаться.

В целом, преимущество нормального порядка по сравнению с аппликативным заключается в отбрасывании веток вычисления, которые не будут использованы в итоговом вычислении (так называемый "мёртвый код"). Интуитивно, нормальный порядок является ленивым, то есть не будет вычислять аргументы абстракций до того, как они непосредственно понадобятся. Это позволяет ему не вычислять ветки вычисления, которые не используются в итоге, как и было проиллюстрированно в примере выше. На практике такие неиспользуемые ветки вычисления могут соответствовать, к примеру, проекциям структуры (в этом случае вычисления в полях, не задействованных в проекции, становятся бесполезными), или условным операторам с константным условием.

Недостатком же нормального порядка является возможное дублирование подтермов при подстановке, и, соответственно, дубликация работы при редукции этих подтермов. Для примера рассмотрим терм $\omega ((\lambda y.\, y) x)$: $$\omega ((\lambda y.\, y) x) \rightarrow_{\beta_{appl}} \omega x \rightarrow_{\beta_{appl}} x x$$ $$ \omega ((\lambda y.\, y) x) \rightarrow_{\beta_{norm}} ((\lambda y.\, y) x) ((\lambda y.\, y) x) \rightarrow_{\beta_{norm}} x ((\lambda y.\, y) x) \rightarrow_{\beta_{norm}} x x$$

В нормальном порядке из-за преждевременной подстановки не приведённого к нормальной форме подтерма $((\lambda y.\, y) x)$ оказались удвоенными вычисления, направленные на редукцию этого терма. А если рассмотреть редукцию терма $\underbrace{\omega\omega\cdots\omega\,}_\text{$n$ раз}((\lambda y.\, y) x)$, то редукция в нормальном порядке повторит редукцию этого подтерма $2^n$ раз, то есть в таких случаях нормальный порядок будет экспоненциально менее производительным, чем аппликативный.

Чтобы решить эту проблему, в некоторых языках, например в Haskell \cite{haskell}, вводится мемоизация для результатов редукции подтермов, то есть результат однажды редуцированного подтерма используется при редукции его копий. Такая модификация вызова по имени называется \textit{вызов по необходимости} (\textit{call-by-need}). Такие техники могут быть реализованы достаточно сложными алгоритмами, добавляющими определённые накладные расходы на производительность и использование памяти, поэтому они используются не всегда, однако они решают описанное выше экспоненциальное замедление.

Haskell является одним из немногих языков с порядком вычислений, основанным на нормальном порядке. Большинство других языков программирования, как императивных, так и функциональных используют вызов по значению. В целом, наличие любых императивных примитивов в языке, которые потенциально могут приводить к побочным эффектам, делает применение нормального порядка намного менее привлекательным, поскольку при таком порядке трудно отследить последовательность побочных эффектов. Однако, многие языки, особенно функциональные, позволяют симулировать ленивые вычисления в нормальном порядке для лучшей выразительности и эффективности в отдельных случаях, тогда как вызов по значению используется по умолчанию. Примеры включают модуль \texttt{Lazy} в OCaml, конструкция \texttt{lazy val} в Scala или генераторы списков в Python.

\subsection{Проблемы производительности в Coq} \label{coq_problems}

Интерактивное средство доказательств теорем Coq используется для доказательства математических теорем и формальной верификации программного кода. Теоретическая основа внутреннего языка Coq --- \textit{исчисление индуктивных конструкций} (\textit{calculus of inductive constructions}), типизированный и расширенный вариант лямбда-исчисления.

Исчисление индуктивных конструкций является конфлюэнтным, то есть результат редукции не зависит от порядка редукции, и сильно нормализуемым, то есть любой порядок редукции приведёт к нормальной форме за конечное число шагов \cite{cic_proofs}. В отличие от многих языков общего назначения, Coq не является Тьюринг-полным языком, но при этом позволяет использовать рекурсивные функции при условии, что будет доказана их завершаемость. Это необычное свойство языка продиктовано необходимостью консистентности внутренней логики, однако оно также даёт максимальную свободу при выборе стратегии редукции --- поскольку любая стратегия приведёт к результату за конечное время, можно разработать какие угодно стратегии и выбрать из них наиболее производительную.

Coq предоставляет возможность использовать вызов по необходимости (тактика \\\texttt{lazy}) или вызов по значению (тактика \texttt{cbv}). Разработчики языка утверждают, что стратегия \texttt{cbv} будет эффективнее в чисто вычислительных случаях, то есть почти не содержащих "мёртвый код", а стратегия \texttt{lazy} может показывать результаты лучше в других случаях \cite{coq}, что согласуется с теоретическими соображениями, описанными в разделе \ref{orders}. Во внутренних для системы редукциях при финальной проверки типов доказательства (команда \texttt{Qed}) используется call-by-need стратегия.

Однако, к сожалению, ограничиться выбором подходящей для входных данных стратегии из этих двух вариантов недостаточно. При разработке практических и масштабируемых проектов на Coq нередко можно наткнуться на критические проблемы производительности, вызванные ошибками или особенностями в коде Coq. Например, хотя в Coq применяется вызов по необходимости, мемоизированный вариант вызова по имени, в некоторых ситуациях эквивалентность дублирующихся термов не распознаётся, что приводит к повторной редукции одних и тех же выражений \cite{sharing_bug}. Выше уже было обозначено, к каким нежелательным последствиям может привести отсутствие мемоизации для вызова по имени. В другом случае, из-за недостаточной информации о типах вычисления приобретают экспоненциальную сложность \cite{letform_bug}.

Более подробному исследованию проблем с производительностью в Coq посвящена диссертация Гросса \cite{gross_phd}. В ней, помимо описания множества проблем, подобным двум описанным выше, утверждается, что диагностика таких проблем и их исправление требуют значительного погружения в детали реализации Coq и экспертного знания относительно устройства этой реализации. Такое погружение выходит за рамки данной работы, поэтому в этой работе во многом внутренняя реализация Coq будет восприниматься как "чёрный ящик". Тем не менее, будет продемонстрировано, что даже при таком упрощённом подходе, различные алгоритмы композиции внутренних механизмов Coq показывают результаты, на данной задаче значительно превосходящие эти механизмы по производительности.

Отметим также работы по оптимизации редукций, которые добавили в Coq редукции \texttt{vm\_compute} \cite{vm} и \texttt{native\_compute} \cite{native}. Эти реализации вызова по значению, ориентированные на эффективность и работу с высоконагруженными вычислениями, значительно превосходят по производительности редукцию \texttt{cbv}. Однако, эти редукции было бы затруднительно использовать для символьного вычисления, то есть в контексте этой работы, поскольку для символьного вычисления критически важно объявлять некоторые определения как \textit{непрозрачные} (\textit{opaque}), которые не будут раскрываться в процессе вычисления. Например, на некоторых этапах намного полезнее работать со сложением как с абстрактным символом \texttt{+}, чем с буквальным определением сложения, а при раскрытии таких конструкций крайне затруднена автоматизация. Редукции \texttt{vm\_compute} и \texttt{native\_compute} однако игнорируют непрозрачность определений и редуцируют термы до конца, а потенциальное расширение этих реализаций поддержкой непрозрачности может сильно замедлить эти алгоритмы \cite{opaque}. Поэтому в рамках этой работы не будут использоваться эти тактики, несмотря на их эффективность.

Язык Ltac позволяет расширять набор тактик Coq, то есть создавать программы для автоматической верификации. При этом на него не накладываются ограничения на завершимость, поэтому разработка алгоритмов на нём более напоминает разработку на традиционных языках. В этой работе Ltac будет использован для разработки специализированных стратегий редукции.

\subsection{Система Ursus} \label{ursus}

Система Ursus разработана как расширение системы Coq и предназначена для верификации смарт-контрактов на различных языках. Она включает в себя:
\begin{itemize}
    \item внутренний монадический язык;
    \item транслятор, позволяющий автоматически получать из исходного кода смарт-контрактов на языках Solidity, Rust, FunC аналогичный код на внутреннем языке Ursus;
    \item аналоги стандартных библиотек для этих языков, сформулированных на Coq или Ursus, с заранее доказанными фактами о содержимом этих библиотек;
    \item интерпретатор для языка Ursus;
    \item язык для написания спецификаций;
    \item \textit{генератор вычислений} (\textit{exec generator}), позволяющий преобразовывать функции на языке Ursus в набор уравнений, описывающих изменения в системе на каждом шагу (с автоматически доказанной эквивалентностью результату интерпретации функции);
    \item алгоритм, который позволяет упростить систему уравнений, полученную из генератора вычислений, относительно конкретного элемента спецификации, тем самым упростив работу верификатора (символьное вычисление).
\end{itemize}

Эта работа посвящена оптимизации последнего шага из списка выше, а поскольку этот шаг принимает как входные данные систему уравнений из генератора вычислений, необходимо остановиться на его описании подробнее. Проиллюстрируем работу генератора вычислений на простом примере. Возьмём небольшую функцию на исходном языке Solidity:

\begin{minted}{solidity}
uint64 result;
function f(uint64 a, uint64 b) {
    uint64 x = result;
    x = x + a;
    x = x - b;
    result = x;
}
\end{minted}

После того, как эта функция будет транслирована на язык Ursus, генератор вычислений создаст на её основе следующую систему уравнений (конкретные выражения заменены текстовыми описаниями для краткости):
\bigskip\\
\newenvironment{allintypewriter}{\ttfamily}{}\begin{allintypewriter}\textcolor{magenta}{y1} = стартовое состояние системы\\
\textcolor{magenta}{y2} = указатель на глобальную переменную \textcolor{violet}{result}\\
\textcolor{magenta}{y3} = \textcolor{magenta}{y1}, в котором создана новая переменная \textcolor{teal}{x} со значением \textcolor{magenta}{y2}\\
\textcolor{magenta}{y4} = указатель на состояние переменной \textcolor{teal}{x} в \textcolor{magenta}{y3}\\
\textcolor{magenta}{y5} = значение указателя \textcolor{magenta}{y4}\\
\textcolor{magenta}{y6} = \textcolor{magenta}{y5} + \textcolor{cyan}{a}\\
\textcolor{magenta}{y7} = \textcolor{magenta}{y3}, в котором значение переменной \textcolor{teal}{x} заменено на \textcolor{magenta}{y6}\\
\textcolor{magenta}{y8} = указатель на состояние переменной \textcolor{teal}{x} в \textcolor{magenta}{y7}\\
\textcolor{magenta}{y9} = значение указателя \textcolor{magenta}{y8}\\
\textcolor{magenta}{y10} = \textcolor{magenta}{y9} - \textcolor{cyan}{b}\\
\textcolor{magenta}{y11} = \textcolor{magenta}{y7}, в котором значение переменной \textcolor{teal}{x} заменено на \textcolor{magenta}{y10}\\
\textcolor{magenta}{y12} = указатель на состояние переменной \textcolor{teal}{x} в \textcolor{magenta}{y11}\\
\textcolor{magenta}{y13} = значение указателя \textcolor{magenta}{y12}\\
\textcolor{magenta}{y14} = \textcolor{magenta}{y11}, в котором значение глобальной переменной \textcolor{violet}{result} заменено на \textcolor{magenta}{y13}\\
\textcolor{magenta}{y15} = \textcolor{magenta}{y14} (итоговое состояние системы)
\end{allintypewriter}
\bigskip

Такая низкоуровневая декомпозиция исходной функции отдалённо напоминает код на языках ассемблера. В отличие от них, здесь отсуствует какой-либо стек или хранилище данных, а каждая очередная вводимая формула может использовать значения всех формул, введённых выше.

Теперь перейдём к верификации корректности этой функции. Единственный наблюдаемый эффект от запуска этой функции --- изменение значения глобальной переменной \texttt{result}. То есть, полная спецификация корректности этой функции заключается в следующем факте: если значение \texttt{result} в стартовом состоянии \texttt{y1} равно $r$, то значение \texttt{result} в финальном состоянии \texttt{y15} должно равняться $r + a - b$. Для того, чтобы доказать этот факт, необходимо упростить систему путём подстановки определений $y_i$ и редукции соответствующих термов.

В общем случае, входные данные для упрощения системы уравнений состоят из двух частей. Во-первых, система уравнений $Y$ вида $y_i = T_i(y_1, y_2, \dots, y_{i - 1})$, где $T_i$ —-- некоторый терм, который может содержать как свободные переменные $y_j$ для $j < i$. Во-вторых, спецификация $P(y_1, y_2, \dots, y_n)$, где $P$ это произвольный терм, который может содержать любые переменные $y_i$. Задача же упрощения системы состоит в редукции терма спецификации $P(y_1, y_2, \dots, y_n)$ с использованием определений $y_i$.

Зачастую в реальных задачах, как и в рассматриваемом примере, спецификация имеет вид $P(y_1, y_n)$, то есть является отношением между стартовым и финальным состоянием, описывающим поведение функции. Однако, в некоторых случаях, если для спецификации важно промежуточное состояние, например при вызове внутренней функции после изменения глобального состояния, в спецификации также могут использоваться переменные $y_i$ для $1 < i < n$. Руководствуясь этими практическими соображениями, будем решать задачу в общем виде.

Заметим, что спецификация для этой функции является достаточно тривиальной, и её верность окажется очевидной, как только будут упрощена система уравнений. Действительно, в этом случае после упрощения достаточно будет применить тактику для доказательства тривиальных фактов \texttt{auto}. Тем не менее, даже если спецификация является более сложной, упрощение системы уравнений значительно упростит задачу верификатора, так как специализирует код функции относительно необходимого среза состояния. Например, если свойство спецификации описывает изменение в функции только одной переменной, в результате упрощения все изменения других переменных, не влияющих на специфицированную, будут исключены.

Одно из преимуществ описанной декомпозиции заключается в возможности тонко и точечно настраивать и применять редукцию и вычисления, что и будет продемонстрировано в этой работе. А именно, при разработке стратегий вычисления в следующей главе, нативные стратегии редукции (\texttt{lazy} и \texttt{cbv}) будут применяться лишь для конкретных уравнений и для вычисления итогового результата, в то время как разработанные стратегии будут задавать порядок вычислений, руководствуясь структурой данных, размером входа и другой информацией о конкретной задаче.

\subsection{Выводы и результаты по главе}

Определено нетипизированное лямбда-исчисление, на его примере определены подстановки и $\beta$-редукция. Сформулированы следующие порядки редукций: нормальный порядок и вызов по имени, аппликативный порядок и вызов по значению. Аппликативный порядок может быть неэффективен в случае "мёртвого кода", а нормальный --- в случае дубликации аргументов. Для частичного решения проблем нормального порядка применяется вызов по необходимости. В языке Coq используются оба подхода. Из-за многочисленных и сложных в диагностике и исправлении проблем в производительности Coq было выбрано относиться к нативным редукциям как к "чёрному ящику". Описана система Ursus в целом и входные данные для задачи упрощения системы формул в частности. Для оптимизации этой задачи будем использовать нативные редукции на декомпозированных элементах, а результаты композировать различными, разработанными в следующей главе способами.

\end{document}
